from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from pprint import pprint
from pathlib import Path
import pandas as pd
import json

def extract_ember(rows):

    data_path = Path.home() / "ember_dataset" / "train_features_1.jsonl" 
    with open(data_path, "r") as f:
        for line in f:
            sample = json.loads(line);
        
            text_entropy = 0;
            rsrc_entropy = 0;

            #Scanning Entropy
            for sec in sample.get("section", {}).get("sections", []):
                if sec["name"] == ".text":
                    text_entropy = sec.get("entropy", 0)
                elif sec["name"] == ".rsrc":
                    rsrc_entropy = sec.get("entropy", 0)
        
            rows.append({
                "file_size": sample["general"].get("size", 0),
                "virtual_size": sample["general"].get("vsize", 0),
                "imports": sample["general"].get("imports", 0),
                "exports": sample["general"].get("exports", 0),
                "sections": len(sample["section"]["sections"]) if "section" in sample else 0,
                "has_signature": sample["general"].get("has_signature", 0),
                "has_tls": sample["general"].get("has_tls", 0),
                "text_entropy": text_entropy,
                "rsrc_entropy": rsrc_entropy,
                "malicious": sample["label"]
            })
    return rows;

def knn_classifier(features):

    rows = [];
    rows = extract_ember(rows);

    data = pd.DataFrame(rows);
    data = data[data["malicious"] >= 0]

    #Getting features and target
    X = data.drop("malicious", axis = 1)
    y = data["malicious"]

    #Train Test Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

    #Feature Scaling
    sc = StandardScaler();
    X_train = sc.fit_transform(X_train);
    X_test = sc.transform(X_test);

    #KNN Model Training
    knn = KNeighborsClassifier(n_neighbors = 25, algorithm = 'kd_tree')
    knn.fit(X_train, y_train)

    #Predicting
    feats = [[
        features["file_size"], 
        features["virtual_size"], 
        features["imports"],
        features["exports"],
        features["sections"],
        features["has_signature"],
        features["has_tls"],
        features["text_entropy"],
        features["rsrc_entropy"]
    ]]

    feat_scaled = sc.transform(feats);
    feat_pred = knn.predict(feat_scaled);
    y_pred = knn.predict(X_test);

    return feat_pred;
